#!/usr/bin/env python3
"""
AI Product Description Generator
Supports local Ollama and fallback to OpenRouter with retry logic
"""

import requests
import time
import logging
from typing import Dict, Any, Optional
from dataclasses import dataclass

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class AIConfig:
    # Local Ollama settings
    ollama_url: str = "http://localhost:11434/v1/chat/completions"
    ollama_model: str = "llama3.2:3b"  # or "mistral:7b", "codellama:7b"
    
    # OpenRouter fallback settings
    openrouter_url: str = "https://openrouter.ai/api/v1/chat/completions"
    openrouter_key: str = ""  # Set your API key here
    openrouter_model: str = "mistralai/mixtral-8x7b-instruct"  # or "nousresearch/nous-hermes-2-mixtral-8x7b-dpo"
    
    # Request settings
    timeout: int = 30
    max_retries: int = 3
    retry_delay: float = 1.0

class AIDescriptionGenerator:
    def __init__(self, config: AIConfig = None):
        self.config = config or AIConfig()
    
    def generate_description(self, product_title: str, category: str, language: str = "en") -> Dict[str, Any]:
        """Generate product description with local LLM first, fallback to OpenRouter"""
        
        # Try local Ollama first
        result = self._try_local_llm(product_title, category, language)
        if result['success']:
            logger.info("‚úÖ Generated description using local Ollama")
            return result
        
        # Fallback to OpenRouter
        logger.warning("‚ö†Ô∏è Local LLM failed, trying OpenRouter fallback")
        result = self._try_openrouter(product_title, category, language)
        if result['success']:
            logger.info("‚úÖ Generated description using OpenRouter")
            return result
        
        # Both failed
        logger.error("‚ùå Both local and remote AI services failed")
        return {
            'success': False,
            'error': 'All AI services unavailable',
            'description': self._fallback_description(product_title, category, language)
        }
    
    def _try_local_llm(self, product_title: str, category: str, language: str) -> Dict[str, Any]:
        """Try local Ollama LLM"""
        try:
            prompt = self._build_prompt(product_title, category, language)
            
            payload = {
                "model": self.config.ollama_model,
                "messages": [{"role": "user", "content": prompt}],
                "temperature": 0.7,
                "max_tokens": 200
            }
            
            return self._make_request(self.config.ollama_url, payload, headers={}, service="Ollama")
            
        except Exception as e:
            logger.error(f"Local LLM error: {str(e)}")
            return {'success': False, 'error': str(e)}
    
    def _try_openrouter(self, product_title: str, category: str, language: str) -> Dict[str, Any]:
        """Try OpenRouter as fallback"""
        if not self.config.openrouter_key:
            return {'success': False, 'error': 'OpenRouter API key not configured'}
        
        try:
            prompt = self._build_prompt(product_title, category, language)
            
            payload = {
                "model": self.config.openrouter_model,
                "messages": [{"role": "user", "content": prompt}],
                "temperature": 0.7,
                "max_tokens": 200
            }
            
            headers = {
                "Authorization": f"Bearer {self.config.openrouter_key}",
                "Content-Type": "application/json"
            }
            
            return self._make_request(self.config.openrouter_url, payload, headers, service="OpenRouter")
            
        except Exception as e:
            logger.error(f"OpenRouter error: {str(e)}")
            return {'success': False, 'error': str(e)}
    
    def _make_request(self, url: str, payload: dict, headers: dict, service: str) -> Dict[str, Any]:
        """Make API request with retry logic"""
        
        for attempt in range(self.config.max_retries):
            try:
                logger.info(f"üîÑ Attempting {service} request (attempt {attempt + 1}/{self.config.max_retries})")
                
                start_time = time.time()
                response = requests.post(
                    url, 
                    json=payload, 
                    headers=headers, 
                    timeout=self.config.timeout
                )
                response_time = time.time() - start_time
                
                logger.info(f"‚è±Ô∏è {service} response time: {response_time:.2f}s")
                
                if response.status_code == 200:
                    data = response.json()
                    description = data['choices'][0]['message']['content'].strip()
                    
                    return {
                        'success': True,
                        'description': description,
                        'service': service,
                        'model': payload['model'],
                        'response_time': response_time,
                        'tokens_used': data.get('usage', {}).get('total_tokens', 0)
                    }
                else:
                    logger.warning(f"‚ö†Ô∏è {service} HTTP {response.status_code}: {response.text}")
                    
            except requests.exceptions.Timeout:
                logger.warning(f"‚è∞ {service} timeout (attempt {attempt + 1})")
            except requests.exceptions.ConnectionError:
                logger.warning(f"üîå {service} connection error (attempt {attempt + 1})")
            except Exception as e:
                logger.error(f"‚ùå {service} unexpected error: {str(e)}")
            
            # Wait before retry (except last attempt)
            if attempt < self.config.max_retries - 1:
                time.sleep(self.config.retry_delay * (attempt + 1))  # Exponential backoff
        
        return {'success': False, 'error': f'{service} failed after {self.config.max_retries} attempts'}
    
    def _build_prompt(self, product_title: str, category: str, language: str) -> str:
        """Build AI prompt for product description"""
        
        if language == "hi":
            return f"""‡§Ü‡§™ ‡§è‡§ï ‡§à-‡§ï‡•â‡§Æ‡§∞‡•ç‡§∏ ‡§™‡•ç‡§∞‡•ã‡§°‡§ï‡•ç‡§ü ‡§°‡§ø‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§∂‡§® ‡§è‡§ï‡•ç‡§∏‡§™‡§∞‡•ç‡§ü ‡§π‡•à‡§Ç‡•§ 

‡§™‡•ç‡§∞‡•ã‡§°‡§ï‡•ç‡§ü: {product_title}
‡§ï‡•à‡§ü‡•á‡§ó‡§∞‡•Ä: {category}

‡§ï‡•É‡§™‡§Ø‡§æ ‡§á‡§∏ ‡§™‡•ç‡§∞‡•ã‡§°‡§ï‡•ç‡§ü ‡§ï‡•á ‡§≤‡§ø‡§è ‡§è‡§ï ‡§Ü‡§ï‡§∞‡•ç‡§∑‡§ï ‡§î‡§∞ ‡§µ‡§ø‡§∏‡•ç‡§§‡•É‡§§ ‡§µ‡§ø‡§µ‡§∞‡§£ ‡§≤‡§ø‡§ñ‡•á‡§Ç ‡§ú‡•ã:
- ‡§ó‡•ç‡§∞‡§æ‡§π‡§ï‡•ã‡§Ç ‡§ï‡•ã ‡§ñ‡§∞‡•Ä‡§¶‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§™‡•ç‡§∞‡•á‡§∞‡§ø‡§§ ‡§ï‡§∞‡•á
- ‡§™‡•ç‡§∞‡•ã‡§°‡§ï‡•ç‡§ü ‡§ï‡•Ä ‡§µ‡§ø‡§∂‡•á‡§∑‡§§‡§æ‡§ì‡§Ç ‡§ï‡•ã ‡§π‡§æ‡§á‡§≤‡§æ‡§á‡§ü ‡§ï‡§∞‡•á  
- ‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§ó‡•ç‡§∞‡§æ‡§π‡§ï‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§â‡§™‡§Ø‡•Å‡§ï‡•ç‡§§ ‡§π‡•ã
- 50-80 ‡§∂‡§¨‡•ç‡§¶‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§π‡•ã

‡§ï‡•á‡§µ‡§≤ ‡§µ‡§ø‡§µ‡§∞‡§£ ‡§¶‡•á‡§Ç, ‡§ï‡•ã‡§à ‡§Ö‡§§‡§ø‡§∞‡§ø‡§ï‡•ç‡§§ ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§®‡§π‡•Ä‡§Ç‡•§"""
        else:
            return f"""You are an e-commerce product description expert.

Product: {product_title}
Category: {category}

Please write an engaging and detailed product description that:
- Motivates customers to purchase
- Highlights key product features
- Appeals to Indian customers
- Is 50-80 words long

Provide only the description, no additional text."""
    
    def _fallback_description(self, product_title: str, category: str, language: str) -> str:
        """Generate basic fallback description when AI fails"""
        if language == "hi":
            return f"‡§Ø‡§π ‡§è‡§ï ‡§â‡§ö‡•ç‡§ö ‡§ó‡•Å‡§£‡§µ‡§§‡•ç‡§§‡§æ ‡§ï‡§æ {product_title} ‡§π‡•à ‡§ú‡•ã {category} ‡§∂‡•ç‡§∞‡•á‡§£‡•Ä ‡§Æ‡•á‡§Ç ‡§Ü‡§§‡§æ ‡§π‡•à‡•§ ‡§Ø‡§π ‡§â‡§§‡•ç‡§™‡§æ‡§¶ ‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§ó‡•ç‡§∞‡§æ‡§π‡§ï‡•ã‡§Ç ‡§ï‡•Ä ‡§ú‡§∞‡•Ç‡§∞‡§§‡•ã‡§Ç ‡§ï‡•ã ‡§ß‡•ç‡§Ø‡§æ‡§® ‡§Æ‡•á‡§Ç ‡§∞‡§ñ‡§ï‡§∞ ‡§¨‡§®‡§æ‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à‡•§"
        else:
            return f"This is a high-quality {product_title} in the {category} category. This product is designed keeping Indian customers' needs in mind."

def main():
    """Demo the AI description generator"""
    
    # Configure (set your OpenRouter key if you have one)
    config = AIConfig(
        openrouter_key="",  # Add your key here for fallback
        ollama_model="llama3.2:3b"  # Change based on your Ollama setup
    )
    
    generator = AIDescriptionGenerator(config)
    
    # Test cases
    test_products = [
        ("Handwoven Silk Saree", "Clothing", "en"),
        ("‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä ‡§ï‡§æ ‡§¶‡•Ä‡§Ø‡§æ", "Home Decor", "hi"),
        ("Kashmiri Pashmina Shawl", "Accessories", "en"),
        ("‡§π‡§∏‡•ç‡§§‡§®‡§ø‡§∞‡•ç‡§Æ‡§ø‡§§ ‡§≤‡§ï‡§°‡§º‡•Ä ‡§ï‡•Ä ‡§Æ‡•Ç‡§∞‡•ç‡§§‡§ø", "Art & Crafts", "hi")
    ]
    
    print("üöÄ AI Product Description Generator Demo\n")
    
    for title, category, language in test_products:
        print(f"üì¶ Product: {title} ({category}) - Language: {language}")
        print("-" * 60)
        
        result = generator.generate_description(title, category, language)
        
        if result['success']:
            print(f"‚úÖ Success via {result.get('service', 'Unknown')}")
            print(f"üìù Description: {result['description']}")
            if 'response_time' in result:
                print(f"‚è±Ô∏è Response time: {result['response_time']:.2f}s")
            if 'tokens_used' in result:
                print(f"üî¢ Tokens used: {result['tokens_used']}")
        else:
            print(f"‚ùå Failed: {result['error']}")
            print(f"üìù Fallback: {result.get('description', 'No fallback available')}")
        
        print("\n")

if __name__ == "__main__":
    main()